package com.corundumstudio.socketio.demo;

import java.util.Arrays;
import java.util.Properties;
import java.util.concurrent.Executor;
import java.util.concurrent.Executors;
import java.util.concurrent.ThreadFactory;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

public class ProducerWorker {
	
	/*
	

	public static void startProducer() {
		
		Properties props=new Properties();
		
		props.put("bootstrap.servers", "localhost:9092");
		props.put("acks", "all");
		props.put("retries", "0");
		props.put("batch.size", 16384);
		props.put("linger.ms", 0);
		props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		
		
		Executor myexec = Executors.newFixedThreadPool(100, new ThreadFactory() {
			@Override
			public Thread newThread(Runnable r) {
				final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
				return new KafkaProducerThread(consumer);
			}
		});
		for (int i = 0; i < 100; i++) {
			myexec.execute(new Runnable() {
				@Override
				public void run() {
				}
			});
		}

	}
	
	private static class KafkaProducerThread extends Thread {
		KafkaProducer<String, String> producer;
		
		public KafkaProducerThread(KafkaProducer<String, String> consumer) {
			System.out.println("creating thread");
			this.consumer = consumer;
		}
		
		@Override
		public void run() {try {
			consumer.subscribe(Arrays.asList("hazem"));
			while(true) {
				ConsumerRecords<String, String> records = consumer.poll(1000000);
				for (ConsumerRecord<String, String> record : records) {
					System.out.println(record.value());
				}
				}
			} 
			catch(Exception e){
				e.printStackTrace();
			}
			finally {
				//consumer.close();
			}
		}
	}*/
	
	
}
